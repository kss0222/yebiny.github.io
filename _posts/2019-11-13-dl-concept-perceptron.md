---
layout: post
title:  "[딥러닝 개요] 1. Perceptron"
subtitle:  ""
categories: dl
tags: concept
---

현재 인공지능 분야에서 가장 널리 쓰이고 있는 각종 복잡한 딥러닝 알고리즘들은 수십년전 퍼셉트론부터 시작한다. 따라서 딥러닝을 시작하기 위해서는 초기 인공신경망인 `Perceptron` 개념에 대해서 먼저 이해할 필요가 있다.


## (1) 개요
---

### 사람의 뇌를 모방하다.

사람의 뇌는 신경계를 구성하는 주된 세포인 뉴런을 약 1000억개 정도 가지고 있으며 각 뉴런들은 어떤 신호를 입력 받고 그에 대한 신호를 출력한다. 

![03]({{ site.url }}/assets/perception-03.PNG)

이러한 개념을 기반으로 1957년에 코넬 항공 연구소(Cornell Aeronautical Lab)의 프랑크 로젠블라트 (Frank Rosenblatt)는 초기 형태의 인공신경망을 제안하였다. 다수 입력으로 부터 하나의 결과를 내보내는 알고리즘이며 이를 도식화한 그림은 아래와 같다. 

### 가중치와 활성함수

그림에 대한 설명을 하자면, $$x$$는 입력 데이터이고 $$w$$ 는 각 $$x$$에대한 가중치(weigth)이며 $$wx$$를 모두 더하는 함수를 `순입력 함수` (net input 함수) 라고 한다. 그리고 순입력 함수에서 나온 값을 다시 `활성 함수`로 보내고 이렇게 나온 값이 예측값이 된다. 

활성함수는 보통 0이나 1을 출력하게 된다. 초기 인공 신경망 모델인 퍼셉트론은 활성화 함수로 계단 함수(step function)을 사용하였다. (아래 그림 참조) 계단함수는 어떤 임계치를 넘으면 1을 출력하고 그렇지 않을 경우 0을 출력한다.  

![05]({{ site.url }}/assets/perception-05.PNG)

이 간단한 퍼셉트론 모델이 하는 일을 생각해보면 데이터 $$x_i$$ 를 받아 데이터 $$x_i$$ 각각에 대해 가중치 $$w_i$$ 를 곱한 후 그 합을 활성함수를 사용하여 1 이나 0을 도출한다. 간단하지만 이 기본적인 개념을 잘 인식하는게 생각보다 앞으로의 복잡한 딥러닝 모델을 공부하는데 큰 도움이 된다.

## (2) Sigle Layer Perceptron
---

우선 위에서 우리가 만든 퍼셉트론 모델을 좀 더 `딥러닝` 스럽게 그리고 싶은데 사실 현재 딥러닝 노드나 알고리즘들을 표현하는 방법이 비슷하면서도 다양하다. 나는 입력/출력 데이터 값은 네모, 함수는 원으로 통일하는 걸 선호하는 편이다. 따라서 위의 간단한 단층 perception을 다음과 같이 그릴 수 있다.

![02]({{ site.url }}/assets/perception-02.PNG)

그런데 여기서 보통 가중치 합 함수와 활성함수는 거의 함께 사용되기 때문에 이렇게 표현할 수도 있다.

![01]({{ site.url }}/assets/perception-01.PNG)

이 그림이 내가 선호하는 딥러닝 네트워크 표현 방식이다. 그림에서 데이터가 입력되는 층을 `Input Layer`, 가운데 노드를 `Hidden Layer`, 값이 출력되는 층을 `Output Layer`라고 한다. Hidden Layer에 있는 perceptron 이 한개이기 때문에 `Single Layer perceptron`이라고 한다. 그럼 이 간단한 모델로 어떤 문제를 풀어볼 수 있을까?

## (3) And, Or 문제
---




## (4) 한계
---
